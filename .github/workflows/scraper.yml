name: Daily Scraper

on:
  schedule:
    - cron: '0 8 * * *'  # every day at 8:00 UTC
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install system dependencies
        run: |
          sudo apt-get update

          sudo apt-get install -y wget gnupg unzip xvfb libxi6 libgconf-2-4 libnss3 libxss1 libappindicator3-1 fonts-liberation
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo dpkg -i google-chrome-stable_current_amd64.deb || sudo apt-get -f install -y
          google-chrome --version
          python -m pip install --upgrade pip


      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt
          pip install webdriver-manager


      - name: Test Chrome and Selenium-Wire
        run: |
          python - <<'PYCODE'
          from seleniumwire import webdriver
          from selenium.webdriver.chrome.options import Options

          options = Options()
          options.add_argument("--headless")
          options.add_argument("--no-sandbox")
          options.add_argument("--disable-dev-shm-usage")

          driver = webdriver.Chrome(options=options)
          driver.get("https://www.google.com")
          print("Captured requests:", len(driver.requests))
          driver.quit()
          PYCODE

      - name: Run scraper
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
          DISPLAY: :99
        run: |
          python -m core.main
